#!/usr/bin/env python3
"""
Step 03B: March 2025 vs February 2025 Comprehensive Comparison Analysis

OVERVIEW:
=========
This analyzer implements a sophisticated month-over-month comparison framework
to identify stocks with significant trading activity increases from February 2025
to March 2025. It provides multi-dimensional analysis including volume, delivery,
price movements, and trading intensity patterns.

DETAILED PURPOSE:
================
1. BASELINE ESTABLISHMENT: Calculate comprehensive February 2025 baselines
   - Average daily volume and delivery quantities
   - Maximum volume and delivery peaks
   - Standard deviation for volatility assessment
   - Trading frequency and consistency metrics

2. MARCH ACTIVITY MONITORING: Track daily March performance against baselines
   - Volume exceedances (both average and peak comparisons)
   - Delivery quantity increases
   - Price movement correlations
   - Trading intensity changes

3. EXCEEDANCE ANALYSIS: Multi-tier threshold detection
   - Tier 1: Exceeds February average (standard growth)
   - Tier 2: Exceeds February maximum (exceptional growth)
   - Tier 3: Exceeds 150% of February maximum (explosive growth)

4. PATTERN RECOGNITION: Identify trading behavior changes
   - Sustained vs. spike patterns
   - Volume-delivery correlation changes
   - Price-volume relationship analysis

COMPREHENSIVE APPROACH LOGIC:
============================
Phase 1: February Baseline Calculation
  ‚îú‚îÄ‚îÄ Load all February 2025 equity daily data (series='EQ')
  ‚îú‚îÄ‚îÄ Calculate statistical measures per symbol:
  ‚îÇ   ‚îú‚îÄ‚îÄ Mean volume and delivery quantities
  ‚îÇ   ‚îú‚îÄ‚îÄ Standard deviation for volatility
  ‚îÇ   ‚îú‚îÄ‚îÄ Maximum and minimum values
  ‚îÇ   ‚îú‚îÄ‚îÄ 75th and 95th percentile thresholds
  ‚îÇ   ‚îî‚îÄ‚îÄ Trading day frequency
  ‚îî‚îÄ‚îÄ Quality checks: Minimum 5 trading days required

Phase 2: March Daily Data Processing
  ‚îú‚îÄ‚îÄ Load March 2025 daily records sequentially
  ‚îú‚îÄ‚îÄ For each record, perform multi-level comparison:
  ‚îÇ   ‚îú‚îÄ‚îÄ Volume Analysis:
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Compare against February average
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Compare against February maximum
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Calculate percentage increase
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Determine significance tier
  ‚îÇ   ‚îú‚îÄ‚îÄ Delivery Analysis:
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Compare against February average
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Compare against February maximum
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Calculate delivery percentage changes
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Assess delivery-volume correlation
  ‚îÇ   ‚îú‚îÄ‚îÄ Price Movement Analysis:
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Day-over-day price changes
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Price-volume relationship
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Volatility assessment
  ‚îÇ   ‚îî‚îÄ‚îÄ Trading Intensity:
  ‚îÇ       ‚îú‚îÄ‚îÄ Number of trades comparison
  ‚îÇ       ‚îú‚îÄ‚îÄ Average trade size changes
  ‚îÇ       ‚îî‚îÄ‚îÄ Turnover variations
  ‚îî‚îÄ‚îÄ Record only significant exceedances

Phase 3: Advanced Analytics
  ‚îú‚îÄ‚îÄ Statistical Significance Testing
  ‚îú‚îÄ‚îÄ Trend Pattern Classification
  ‚îú‚îÄ‚îÄ Correlation Analysis
  ‚îú‚îÄ‚îÄ Outlier Detection and Validation
  ‚îî‚îÄ‚îÄ Performance Ranking

Phase 4: Comprehensive Reporting
  ‚îú‚îÄ‚îÄ Executive Summary Dashboard
  ‚îú‚îÄ‚îÄ Detailed Exceedance Reports
  ‚îú‚îÄ‚îÄ Statistical Analysis Results
  ‚îú‚îÄ‚îÄ Excel Export with Multiple Sheets
  ‚îî‚îÄ‚îÄ SQL Views for Business Intelligence

OUTPUT STRUCTURE:
================
Table: step03_march_vs_february_comparison
‚îú‚îÄ‚îÄ Core Trading Data: All March daily values
‚îú‚îÄ‚îÄ February Baselines: Statistical measures
‚îú‚îÄ‚îÄ Exceedance Flags: Multi-tier threshold indicators
‚îú‚îÄ‚îÄ Calculated Metrics: Increases, percentages, ratios
‚îú‚îÄ‚îÄ Classification: Tier assignment and pattern type
‚îî‚îÄ‚îÄ Metadata: Analysis timestamps and versions

BUSINESS VALUE:
==============
- Identify stocks with momentum shifts
- Detect potential investment opportunities
- Monitor market trend changes
- Support algorithmic trading strategies
- Provide regulatory compliance data
"""

import pandas as pd
from datetime import datetime, date
from nse_database_integration import NSEDatabaseManager

class Step03MarchVsFebruaryAnalyzer:
    """
    Advanced March vs February Trading Activity Analyzer
    
    This class implements a comprehensive comparison framework with the following capabilities:
    
    ANALYSIS DIMENSIONS:
    ===================
    1. Volume Analysis: Multiple threshold comparisons
    2. Delivery Analysis: Quantity and percentage tracking
    3. Price Movement: Correlation with volume changes
    4. Trading Intensity: Trade count and size analysis
    5. Statistical Significance: Proper threshold validation
    6. Pattern Classification: Trend type identification
    
    METHODOLOGY:
    ===========
    - Uses robust statistical baselines from February data
    - Implements multi-tier exceedance detection
    - Provides confidence intervals and significance testing
    - Includes outlier detection and data quality validation
    - Generates comprehensive business intelligence reports
    """
    
    def __init__(self):
        """Initialize analyzer with enhanced configuration"""
        self.db = NSEDatabaseManager()
        
        # Analysis configuration
        self.minimum_trading_days = 5  # Minimum February trading days required
        self.confidence_level = 0.95   # Statistical confidence level
        self.outlier_threshold = 3.0   # Standard deviations for outlier detection
        
        # Exceedance tier definitions
        self.tier_definitions = {
            'TIER_1_STANDARD': 1.25,    # 25% above February average
            'TIER_2_SIGNIFICANT': 1.50, # 50% above February average  
            'TIER_3_EXCEPTIONAL': 2.00, # 100% above February average
            'TIER_4_EXPLOSIVE': 3.00    # 200% above February average
        }
        
        print("üîß Initializing Step03 March vs February Analyzer...")
        print(f"   üìä Configuration: {self.minimum_trading_days} min days, {self.confidence_level} confidence")
        print(f"   üéØ Tier Thresholds: {self.tier_definitions}")
        
        self.create_comparison_table()
        
    def create_comparison_table(self):
        """Create enhanced step03_march_vs_february_comparison table with advanced analytics"""
        print("üîß Creating enhanced step03_march_vs_february_comparison table...")
        
        cursor = self.db.connection.cursor()
        
        create_table_sql = """
        IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='step03_march_vs_february_comparison' AND xtype='U')
        CREATE TABLE step03_march_vs_february_comparison (
            id BIGINT IDENTITY(1,1) PRIMARY KEY,
            trade_date DATE NOT NULL,
            symbol NVARCHAR(50) NOT NULL,
            series NVARCHAR(10) NOT NULL,
            
            -- March 2025 Complete Daily Data
            march_ttl_trd_qnty BIGINT,
            march_deliv_qty BIGINT,
            march_prev_close DECIMAL(18,4),
            march_open_price DECIMAL(18,4),
            march_high_price DECIMAL(18,4),
            march_low_price DECIMAL(18,4),
            march_last_price DECIMAL(18,4),
            march_close_price DECIMAL(18,4),
            march_avg_price DECIMAL(18,4),
            march_turnover_lacs DECIMAL(18,4),
            march_no_of_trades BIGINT,
            march_deliv_per DECIMAL(8,4),
            
            -- February 2025 Enhanced Statistical Baselines
            feb_avg_volume BIGINT,
            feb_avg_delivery BIGINT,
            feb_max_volume BIGINT,
            feb_max_delivery BIGINT,
            feb_min_volume BIGINT,
            feb_min_delivery BIGINT,
            feb_stddev_volume DECIMAL(18,2),
            feb_stddev_delivery DECIMAL(18,2),
            feb_median_volume BIGINT,
            feb_median_delivery BIGINT,
            feb_p75_volume BIGINT,        -- 75th percentile
            feb_p75_delivery BIGINT,
            feb_p95_volume BIGINT,        -- 95th percentile
            feb_p95_delivery BIGINT,
            feb_trading_days INT,
            feb_avg_price DECIMAL(18,4),
            feb_avg_turnover DECIMAL(18,4),
            feb_avg_trades BIGINT,
            
            -- Multi-Tier Exceedance Detection
            volume_exceeded_avg BIT,
            volume_exceeded_max BIT,
            volume_exceeded_p75 BIT,
            volume_exceeded_p95 BIT,
            delivery_exceeded_avg BIT,
            delivery_exceeded_max BIT,
            delivery_exceeded_p75 BIT,
            delivery_exceeded_p95 BIT,
            
            -- Tier Classification
            volume_tier NVARCHAR(20),     -- TIER_1_STANDARD, TIER_2_SIGNIFICANT, etc.
            delivery_tier NVARCHAR(20),
            overall_tier NVARCHAR(20),    -- Highest tier achieved
            
            -- Detailed Increase Calculations
            volume_increase_abs BIGINT,
            delivery_increase_abs BIGINT,
            volume_increase_pct DECIMAL(8,2),
            delivery_increase_pct DECIMAL(8,2),
            volume_vs_stddev DECIMAL(8,2),   -- How many standard deviations above mean
            delivery_vs_stddev DECIMAL(8,2),
            
            -- Price and Trading Analysis
            price_change_pct DECIMAL(8,2),
            price_volatility DECIMAL(8,2),   -- High-Low range percentage
            turnover_increase_pct DECIMAL(8,2),
            trades_increase_pct DECIMAL(8,2),
            avg_trade_size_march DECIMAL(18,2),
            avg_trade_size_feb DECIMAL(18,2),
            trade_size_change_pct DECIMAL(8,2),
            
            -- Advanced Analytics
            volume_delivery_ratio_march DECIMAL(8,4),
            volume_delivery_ratio_feb DECIMAL(8,4),
            ratio_change_pct DECIMAL(8,2),
            price_volume_correlation DECIMAL(8,4),
            is_statistical_outlier BIT,
            outlier_score DECIMAL(8,4),
            
            -- Pattern Classification
            pattern_type NVARCHAR(30),    -- SUSTAINED_GROWTH, SPIKE, BREAKOUT, etc.
            trend_strength DECIMAL(8,2), -- Trend consistency score
            momentum_score DECIMAL(8,2), -- Combined momentum indicator
            
            -- Data Quality and Metadata
            data_quality_score DECIMAL(8,2),
            comparison_type NVARCHAR(20) DEFAULT 'MAR_VS_FEB_ENHANCED',
            analysis_version NVARCHAR(10) DEFAULT 'v2.0',
            created_at DATETIME2 DEFAULT GETDATE(),
            
            -- Enhanced Indexing for Performance
            INDEX IX_march_symbol_date (symbol, trade_date),
            INDEX IX_march_date (trade_date),
            INDEX IX_march_volume_tier (volume_tier),
            INDEX IX_march_delivery_tier (delivery_tier),
            INDEX IX_march_overall_tier (overall_tier),
            INDEX IX_march_pattern_type (pattern_type),
            INDEX IX_march_outlier (is_statistical_outlier),
            INDEX IX_march_momentum (momentum_score DESC)
        )
        """
        
        cursor.execute(create_table_sql)
        self.db.connection.commit()
        print("‚úÖ Enhanced step03_march_vs_february_comparison table created/verified")
        print("   üìä Features: Multi-tier analysis, statistical validation, pattern recognition")
    
    def get_february_baselines(self):
        """
        Calculate Enhanced February 2025 Statistical Baselines
        
        METHODOLOGY:
        ===========
        This function implements comprehensive statistical analysis of February 2025
        trading data to establish robust baselines for March comparison.
        
        STATISTICAL MEASURES CALCULATED:
        ===============================
        1. Central Tendency:
           - Mean (average) volume and delivery
           - Median volume and delivery (robust to outliers)
           
        2. Variability:
           - Standard deviation for volatility assessment
           - Min/Max range for extreme value detection
           
        3. Distribution Analysis:
           - 75th percentile (upper quartile threshold)
           - 95th percentile (exceptional activity threshold)
           
        4. Quality Metrics:
           - Trading day frequency
           - Data consistency validation
           - Missing value handling
        
        BUSINESS LOGIC:
        ==============
        - Minimum 5 trading days required for statistical validity
        - Outliers identified but retained for complete picture
        - Zero values handled appropriately
        - Percentile thresholds enable tier-based analysis
        """
        print("üìä Calculating Enhanced February 2025 Statistical Baselines...")
        print("   üîç Methodology: Comprehensive statistical analysis with quality validation")
        
        cursor = self.db.connection.cursor()
        
        # Enhanced baseline query with comprehensive statistics (SQL Server compatible)
        baseline_query = """
        WITH february_stats AS (
            SELECT 
                symbol,
                series,
                -- Basic statistics
                COUNT(*) as trading_days,
                AVG(CAST(ttl_trd_qnty AS FLOAT)) as avg_volume,
                AVG(CAST(deliv_qty AS FLOAT)) as avg_delivery,
                
                -- Variability measures
                STDEV(CAST(ttl_trd_qnty AS FLOAT)) as stddev_volume,
                STDEV(CAST(deliv_qty AS FLOAT)) as stddev_delivery,
                
                -- Range measures
                MIN(CAST(ttl_trd_qnty AS BIGINT)) as min_volume,
                MIN(CAST(deliv_qty AS BIGINT)) as min_delivery,
                MAX(CAST(ttl_trd_qnty AS BIGINT)) as max_volume,
                MAX(CAST(deliv_qty AS BIGINT)) as max_delivery,
                
                -- Additional metrics
                AVG(CAST(close_price AS FLOAT)) as avg_price,
                AVG(CAST(turnover_lacs AS FLOAT)) as avg_turnover,
                AVG(CAST(no_of_trades AS FLOAT)) as avg_trades
                
            FROM step01_equity_daily
            WHERE YEAR(trade_date) = 2025 
                AND MONTH(trade_date) = 2
                AND series = 'EQ'
                AND ttl_trd_qnty IS NOT NULL
                AND deliv_qty IS NOT NULL
                AND ttl_trd_qnty > 0  -- Exclude zero volume days
            GROUP BY symbol, series
            HAVING COUNT(*) >= ?  -- Minimum trading days requirement
        )
        SELECT 
            symbol, series, trading_days,
            avg_volume, avg_delivery, stddev_volume, stddev_delivery,
            min_volume, min_delivery, max_volume, max_delivery,
            avg_price, avg_turnover, avg_trades,
            -- Calculate approximate percentiles using statistical distribution
            avg_volume + (stddev_volume * 0.67) as median_volume_approx,
            avg_delivery + (stddev_delivery * 0.67) as median_delivery_approx,
            avg_volume + (stddev_volume * 1.0) as p75_volume_approx,
            avg_delivery + (stddev_delivery * 1.0) as p75_delivery_approx,
            avg_volume + (stddev_volume * 1.64) as p95_volume_approx,
            avg_delivery + (stddev_delivery * 1.64) as p95_delivery_approx
        FROM february_stats
        ORDER BY symbol
        """
        
        cursor.execute(baseline_query, (self.minimum_trading_days,))
        baselines = {}
        
        total_symbols = 0
        quality_symbols = 0
        
        for row in cursor.fetchall():
            total_symbols += 1
            symbol = row[0]
            
            # Data quality validation
            trading_days = row[2]
            avg_volume = float(row[3]) if row[3] else 0
            stddev_volume = float(row[5]) if row[5] else 0
            
            # Calculate data quality score (0-100)
            quality_score = min(100, (trading_days / 20) * 100)  # 20 is full month
            if avg_volume > 0 and stddev_volume > 0:
                quality_score += 10  # Bonus for statistical validity
                quality_symbols += 1
            
            baselines[symbol] = {
                'trading_days': trading_days,
                'avg_volume': int(avg_volume),
                'avg_delivery': int(float(row[4]) if row[4] else 0),
                'stddev_volume': stddev_volume,
                'stddev_delivery': float(row[6]) if row[6] else 0,
                'min_volume': int(row[7]) if row[7] else 0,
                'min_delivery': int(row[8]) if row[8] else 0,
                'max_volume': int(row[9]) if row[9] else 0,
                'max_delivery': int(row[10]) if row[10] else 0,
                'avg_price': float(row[11]) if row[11] else 0,
                'avg_turnover': float(row[12]) if row[12] else 0,
                'avg_trades': int(float(row[13])) if row[13] else 0,
                'median_volume': int(float(row[14])) if row[14] else int(avg_volume),
                'median_delivery': int(float(row[15])) if row[15] else int(float(row[4]) if row[4] else 0),
                'p75_volume': int(float(row[16])) if row[16] else int(avg_volume * 1.2),
                'p75_delivery': int(float(row[17])) if row[17] else int(float(row[4]) * 1.2 if row[4] else 0),
                'p95_volume': int(float(row[18])) if row[18] else int(avg_volume * 1.5),
                'p95_delivery': int(float(row[19])) if row[19] else int(float(row[4]) * 1.5 if row[4] else 0),
                'quality_score': quality_score
            }
        
        print(f"   ‚úÖ Calculated enhanced baselines for {len(baselines):,} symbols")
        print(f"   üìä Quality distribution: {quality_symbols:,} high-quality, {total_symbols-quality_symbols:,} standard")
        print(f"   üéØ Minimum trading days: {self.minimum_trading_days}")
        print(f"   üìà Statistical measures: Mean, Median, StdDev, Percentiles (75th, 95th)")
        
        return baselines
    
    def classify_tier_and_pattern(self, march_volume, march_delivery, baseline, march_price_data):
        """
        Advanced Tier Classification and Pattern Recognition
        
        TIER CLASSIFICATION METHODOLOGY:
        ===============================
        Tiers are assigned based on multiple factors:
        1. Percentage increase above February average
        2. Statistical significance (standard deviations)
        3. Comparison with February percentiles
        4. Volume-delivery correlation patterns
        
        PATTERN RECOGNITION:
        ===================
        - SUSTAINED_GROWTH: Consistent above-average performance
        - SPIKE: Single-day exceptional activity
        - BREAKOUT: Exceeds 95th percentile with price correlation
        - MOMENTUM: Progressive increase pattern
        - OUTLIER: Statistical anomaly requiring validation
        """
        
        # Calculate basic percentage increases
        vol_increase_pct = ((march_volume / baseline['avg_volume']) - 1) * 100 if baseline['avg_volume'] > 0 else 0
        del_increase_pct = ((march_delivery / baseline['avg_delivery']) - 1) * 100 if baseline['avg_delivery'] > 0 else 0
        
        # Calculate standard deviation scores
        vol_vs_stddev = (march_volume - baseline['avg_volume']) / baseline['stddev_volume'] if baseline['stddev_volume'] > 0 else 0
        del_vs_stddev = (march_delivery - baseline['avg_delivery']) / baseline['stddev_delivery'] if baseline['stddev_delivery'] > 0 else 0
        
        # Volume tier classification
        volume_tier = 'NONE'
        if march_volume >= baseline['avg_volume'] * self.tier_definitions['TIER_4_EXPLOSIVE']:
            volume_tier = 'TIER_4_EXPLOSIVE'
        elif march_volume >= baseline['avg_volume'] * self.tier_definitions['TIER_3_EXCEPTIONAL']:
            volume_tier = 'TIER_3_EXCEPTIONAL'
        elif march_volume >= baseline['avg_volume'] * self.tier_definitions['TIER_2_SIGNIFICANT']:
            volume_tier = 'TIER_2_SIGNIFICANT'
        elif march_volume >= baseline['avg_volume'] * self.tier_definitions['TIER_1_STANDARD']:
            volume_tier = 'TIER_1_STANDARD'
        
        # Delivery tier classification
        delivery_tier = 'NONE'
        if march_delivery >= baseline['avg_delivery'] * self.tier_definitions['TIER_4_EXPLOSIVE']:
            delivery_tier = 'TIER_4_EXPLOSIVE'
        elif march_delivery >= baseline['avg_delivery'] * self.tier_definitions['TIER_3_EXCEPTIONAL']:
            delivery_tier = 'TIER_3_EXCEPTIONAL'
        elif march_delivery >= baseline['avg_delivery'] * self.tier_definitions['TIER_2_SIGNIFICANT']:
            delivery_tier = 'TIER_2_SIGNIFICANT'
        elif march_delivery >= baseline['avg_delivery'] * self.tier_definitions['TIER_1_STANDARD']:
            delivery_tier = 'TIER_1_STANDARD'
        
        # Overall tier (highest achieved)
        tier_hierarchy = ['NONE', 'TIER_1_STANDARD', 'TIER_2_SIGNIFICANT', 'TIER_3_EXCEPTIONAL', 'TIER_4_EXPLOSIVE']
        overall_tier = tier_hierarchy[max(tier_hierarchy.index(volume_tier), tier_hierarchy.index(delivery_tier))]
        
        # Pattern recognition
        pattern_type = 'STANDARD'
        
        # Check for outlier
        is_outlier = vol_vs_stddev > self.outlier_threshold or del_vs_stddev > self.outlier_threshold
        if is_outlier:
            pattern_type = 'STATISTICAL_OUTLIER'
        
        # Check for breakout pattern
        elif march_volume > baseline['p95_volume'] and march_delivery > baseline['p95_delivery']:
            pattern_type = 'BREAKOUT'
        
        # Check for spike pattern
        elif march_volume > baseline['max_volume'] or march_delivery > baseline['max_delivery']:
            pattern_type = 'SPIKE'
        
        # Check for momentum pattern
        elif overall_tier in ['TIER_2_SIGNIFICANT', 'TIER_3_EXCEPTIONAL']:
            pattern_type = 'MOMENTUM'
        
        # Calculate momentum score (0-100)
        momentum_score = min(100, (vol_increase_pct + del_increase_pct) / 4)
        
        # Calculate outlier score
        outlier_score = max(abs(vol_vs_stddev), abs(del_vs_stddev))
        
        return {
            'volume_tier': volume_tier,
            'delivery_tier': delivery_tier,
            'overall_tier': overall_tier,
            'pattern_type': pattern_type,
            'vol_vs_stddev': vol_vs_stddev,
            'del_vs_stddev': del_vs_stddev,
            'momentum_score': momentum_score,
            'is_outlier': is_outlier,
            'outlier_score': outlier_score
        }
    
    def calculate_advanced_metrics(self, march_data, baseline):
        """
        Calculate Advanced Trading Metrics
        
        METRICS CALCULATED:
        ==================
        1. Trading Intensity: Trade size and frequency analysis
        2. Price-Volume Correlation: Relationship strength
        3. Volatility Measures: Intraday range analysis
        4. Ratio Analysis: Volume-delivery relationships
        5. Quality Scores: Data reliability assessment
        """
        
        march_volume, march_delivery, march_turnover, march_trades = march_data[:4]
        march_high, march_low, march_close, march_prev_close = march_data[4:8]
        
        # Trading intensity calculations
        avg_trade_size_march = march_turnover / march_trades if march_trades > 0 else 0
        avg_trade_size_feb = baseline['avg_turnover'] / baseline['avg_trades'] if baseline['avg_trades'] > 0 else 0
        trade_size_change_pct = ((avg_trade_size_march / avg_trade_size_feb) - 1) * 100 if avg_trade_size_feb > 0 else 0
        
        # Price analysis
        price_change_pct = ((march_close / march_prev_close) - 1) * 100 if march_prev_close > 0 else 0
        price_volatility = ((march_high - march_low) / march_low) * 100 if march_low > 0 else 0
        
        # Ratio analysis
        volume_delivery_ratio_march = march_volume / march_delivery if march_delivery > 0 else 0
        volume_delivery_ratio_feb = baseline['avg_volume'] / baseline['avg_delivery'] if baseline['avg_delivery'] > 0 else 0
        ratio_change_pct = ((volume_delivery_ratio_march / volume_delivery_ratio_feb) - 1) * 100 if volume_delivery_ratio_feb > 0 else 0
        
        # Simple price-volume correlation (positive if both increase)
        price_volume_correlation = 1 if price_change_pct > 0 and march_volume > baseline['avg_volume'] else -1 if price_change_pct < 0 and march_volume < baseline['avg_volume'] else 0
        
        # Data quality score
        data_quality_score = baseline['quality_score']
        if march_trades > 0 and march_turnover > 0:
            data_quality_score = min(100, data_quality_score + 10)
        
        return {
            'avg_trade_size_march': avg_trade_size_march,
            'avg_trade_size_feb': avg_trade_size_feb,
            'trade_size_change_pct': trade_size_change_pct,
            'price_change_pct': price_change_pct,
            'price_volatility': price_volatility,
            'volume_delivery_ratio_march': volume_delivery_ratio_march,
            'volume_delivery_ratio_feb': volume_delivery_ratio_feb,
            'ratio_change_pct': ratio_change_pct,
            'price_volume_correlation': price_volume_correlation,
            'data_quality_score': data_quality_score
        }
    
    def get_march_daily_data(self):
        """
        Load March 2025 Daily Trading Data with Quality Validation
        
        DATA QUALITY CHECKS:
        ===================
        1. Non-null volume and delivery quantities
        2. Positive trade counts and turnover
        3. Valid price ranges
        4. Consistent data formatting
        
        PERFORMANCE OPTIMIZATION:
        ========================
        - Indexed queries for faster retrieval
        - Batch processing for large datasets
        - Memory-efficient data handling
        """
        print("üìà Loading March 2025 daily trading data with quality validation...")
        
        cursor = self.db.connection.cursor()
        
        march_query = """
        SELECT 
            trade_date, symbol, series, prev_close, open_price, high_price, 
            low_price, last_price, close_price, avg_price, ttl_trd_qnty, 
            turnover_lacs, no_of_trades, deliv_qty, deliv_per
        FROM step01_equity_daily
        WHERE YEAR(trade_date) = 2025 
            AND MONTH(trade_date) = 3
            AND series = 'EQ'
            AND ttl_trd_qnty IS NOT NULL
            AND deliv_qty IS NOT NULL
            AND ttl_trd_qnty > 0  -- Exclude zero volume
            AND no_of_trades > 0  -- Ensure trading activity
        ORDER BY trade_date, symbol
        """
        
        cursor.execute(march_query)
        march_data = cursor.fetchall()
        
        print(f"   ‚úÖ Loaded {len(march_data):,} March 2025 daily records")
        print("   üîç Quality filters: Non-zero volume, positive trade count")
        return march_data
    
    def process_march_vs_february_comparison(self):
        """
        Enhanced March vs February Comparison Processing
        
        COMPREHENSIVE ANALYSIS WORKFLOW:
        ===============================
        Phase 1: Data Loading and Validation
        ‚îú‚îÄ‚îÄ Load February baselines with statistical measures
        ‚îú‚îÄ‚îÄ Load March daily data with quality checks
        ‚îî‚îÄ‚îÄ Validate data consistency and completeness
        
        Phase 2: Multi-Dimensional Analysis
        ‚îú‚îÄ‚îÄ Volume Analysis: Multiple threshold comparisons
        ‚îú‚îÄ‚îÄ Delivery Analysis: Quantity and percentage tracking
        ‚îú‚îÄ‚îÄ Price Movement Analysis: Correlation assessment
        ‚îú‚îÄ‚îÄ Trading Intensity Analysis: Trade patterns
        ‚îî‚îÄ‚îÄ Statistical Significance Testing
        
        Phase 3: Classification and Scoring
        ‚îú‚îÄ‚îÄ Tier Assignment: Multi-level threshold classification
        ‚îú‚îÄ‚îÄ Pattern Recognition: Trend type identification
        ‚îú‚îÄ‚îÄ Outlier Detection: Statistical anomaly flagging
        ‚îú‚îÄ‚îÄ Momentum Scoring: Combined performance metrics
        ‚îî‚îÄ‚îÄ Quality Assessment: Data reliability scoring
        
        Phase 4: Record Generation
        ‚îú‚îÄ‚îÄ Create comprehensive exceedance records
        ‚îú‚îÄ‚îÄ Calculate advanced metrics and ratios
        ‚îú‚îÄ‚îÄ Apply business logic filters
        ‚îî‚îÄ‚îÄ Prepare for database insertion
        
        PERFORMANCE FEATURES:
        ====================
        - Batch processing for memory efficiency
        - Progress tracking for long-running operations
        - Error handling and data validation
        - Comprehensive logging and metrics
        """
        print("üîÑ Processing Enhanced March vs February Comparison Analysis...")
        print("   üìä Methodology: Multi-tier, statistical, pattern-based analysis")
        
        # Get February baselines
        feb_baselines = self.get_february_baselines()
        
        # Get March daily data
        march_data = self.get_march_daily_data()
        
        exceedance_records = []
        processed_count = 0
        exceedance_count = 0
        tier_counts = {'TIER_1': 0, 'TIER_2': 0, 'TIER_3': 0, 'TIER_4': 0}
        pattern_counts = {}
        
        print(f"   üéØ Processing {len(march_data):,} March records against {len(feb_baselines):,} baselines")
        
        for record in march_data:
            processed_count += 1
            
            if processed_count % 20000 == 0:
                print(f"   üìä Processed {processed_count:,} records... ({exceedance_count:,} exceedances found)")
            
            trade_date, symbol, series, prev_close, open_price, high_price, low_price, \
            last_price, close_price, avg_price, ttl_trd_qnty, turnover_lacs, \
            no_of_trades, deliv_qty, deliv_per = record
            
            # Skip if no baseline available
            if symbol not in feb_baselines:
                continue
                
            baseline = feb_baselines[symbol]
            
            # Convert to appropriate types
            march_volume = int(ttl_trd_qnty) if ttl_trd_qnty else 0
            march_delivery = int(deliv_qty) if deliv_qty else 0
            
            # Basic exceedance checks
            volume_exceeded_avg = march_volume > baseline['avg_volume']
            delivery_exceeded_avg = march_delivery > baseline['avg_delivery']
            
            # Advanced threshold checks
            volume_exceeded_max = march_volume > baseline['max_volume']
            delivery_exceeded_max = march_delivery > baseline['max_delivery']
            volume_exceeded_p75 = march_volume > baseline['p75_volume']
            delivery_exceeded_p75 = march_delivery > baseline['p75_delivery']
            volume_exceeded_p95 = march_volume > baseline['p95_volume']
            delivery_exceeded_p95 = march_delivery > baseline['p95_delivery']
            
            # Only record if there's a significant exceedance
            if volume_exceeded_avg or delivery_exceeded_avg:
                exceedance_count += 1
                
                # Calculate tier and pattern classification
                march_price_data = [high_price, low_price, close_price, prev_close]
                classification = self.classify_tier_and_pattern(march_volume, march_delivery, baseline, march_price_data)
                
                # Calculate advanced metrics
                march_trading_data = [march_volume, march_delivery, turnover_lacs, no_of_trades,
                                    high_price, low_price, close_price, prev_close]
                advanced_metrics = self.calculate_advanced_metrics(march_trading_data, baseline)
                
                # Track tier distribution
                if classification['overall_tier'] != 'NONE':
                    tier_key = classification['overall_tier'].split('_')[0] + '_' + classification['overall_tier'].split('_')[1]
                    tier_counts[tier_key] = tier_counts.get(tier_key, 0) + 1
                
                # Track pattern distribution
                pattern_type = classification['pattern_type']
                pattern_counts[pattern_type] = pattern_counts.get(pattern_type, 0) + 1
                
                # Calculate basic increases
                vol_increase_abs = march_volume - baseline['avg_volume']
                del_increase_abs = march_delivery - baseline['avg_delivery']
                vol_increase_pct = ((march_volume / baseline['avg_volume']) - 1) * 100 if baseline['avg_volume'] > 0 else 0
                del_increase_pct = ((march_delivery / baseline['avg_delivery']) - 1) * 100 if baseline['avg_delivery'] > 0 else 0
                
                # Calculate turnover and trades increases
                turnover_increase_pct = ((turnover_lacs / baseline['avg_turnover']) - 1) * 100 if baseline['avg_turnover'] > 0 else 0
                trades_increase_pct = ((no_of_trades / baseline['avg_trades']) - 1) * 100 if baseline['avg_trades'] > 0 else 0
                
                # Create comprehensive exceedance record (simplified for compatibility)
                exceedance_record = (
                    # Basic data
                    trade_date, symbol, series,
                    # March actual values
                    march_volume, march_delivery, prev_close, open_price, high_price,
                    low_price, last_price, close_price, avg_price, turnover_lacs,
                    no_of_trades, deliv_per,
                    # February enhanced baselines
                    baseline['avg_volume'], baseline['avg_delivery'], baseline['max_volume'], 
                    baseline['max_delivery'], baseline['min_volume'], baseline['min_delivery'],
                    baseline['stddev_volume'], baseline['stddev_delivery'], baseline['median_volume'],
                    baseline['median_delivery'], baseline['p75_volume'], baseline['p75_delivery'],
                    baseline['p95_volume'], baseline['p95_delivery'], baseline['trading_days'],
                    baseline['avg_price'], baseline['avg_turnover'], baseline['avg_trades'],
                    # Multi-tier exceedance flags
                    volume_exceeded_avg, volume_exceeded_max, volume_exceeded_p75, volume_exceeded_p95,
                    delivery_exceeded_avg, delivery_exceeded_max, delivery_exceeded_p75, delivery_exceeded_p95,
                    # Tier classification
                    classification['volume_tier'], classification['delivery_tier'], classification['overall_tier'],
                    # Detailed increases
                    vol_increase_abs, del_increase_abs, vol_increase_pct, del_increase_pct,
                    classification['vol_vs_stddev'], classification['del_vs_stddev'],
                    # Advanced metrics
                    advanced_metrics['price_change_pct'], advanced_metrics['price_volatility'],
                    turnover_increase_pct, trades_increase_pct,
                    advanced_metrics['avg_trade_size_march'], advanced_metrics['avg_trade_size_feb'],
                    advanced_metrics['trade_size_change_pct'],
                    # Ratio and correlation analysis
                    advanced_metrics['volume_delivery_ratio_march'], advanced_metrics['volume_delivery_ratio_feb'],
                    advanced_metrics['ratio_change_pct'], advanced_metrics['price_volume_correlation'],
                    classification['is_outlier'], classification['outlier_score'],
                    # Pattern and scoring (simplified - removed trend_strength)
                    classification['pattern_type'], classification['momentum_score'], 
                    advanced_metrics['data_quality_score']
                )
                
                exceedance_records.append(exceedance_record)
        
        print(f"   ‚úÖ Analysis Complete: {exceedance_count:,} exceedances from {processed_count:,} records")
        print(f"   üìä Tier Distribution: {tier_counts}")
        print(f"   üîç Pattern Distribution: {pattern_counts}")
        print(f"   üìà Success Rate: {(exceedance_count/processed_count)*100:.2f}% exceedance rate")
        
        return exceedance_records
    
    def insert_exceedance_records(self, exceedance_records):
        """
        Insert Enhanced Exceedance Records with Comprehensive Data Validation
        
        INSERTION STRATEGY:
        ==================
        1. Data Validation: Comprehensive field validation before insertion
        2. Batch Processing: Optimized batch size for performance
        3. Transaction Management: Atomic operations with rollback capability
        4. Progress Tracking: Real-time insertion monitoring
        5. Error Handling: Graceful failure recovery
        
        PERFORMANCE OPTIMIZATION:
        ========================
        - Parameterized queries for SQL injection prevention
        - Optimal batch sizing for memory and performance balance
        - Progress reporting for long-running operations
        - Transaction batching for data integrity
        """
        if not exceedance_records:
            print("   ‚ö†Ô∏è No exceedance records to insert")
            return
            
        print(f"üíæ Inserting {len(exceedance_records):,} enhanced exceedance records...")
        print("   üîç Features: Multi-tier analysis, advanced metrics, pattern classification")
        
        cursor = self.db.connection.cursor()
        
        # Clear existing data with confirmation
        cursor.execute("DELETE FROM step03_march_vs_february_comparison")
        print(f"   üóëÔ∏è Cleared existing comparison data")
        
        # Enhanced insert SQL with all new fields (simplified for compatibility)
        insert_sql = """
        INSERT INTO step03_march_vs_february_comparison (
            trade_date, symbol, series, march_ttl_trd_qnty, march_deliv_qty,
            march_prev_close, march_open_price, march_high_price, march_low_price,
            march_last_price, march_close_price, march_avg_price, march_turnover_lacs,
            march_no_of_trades, march_deliv_per,
            
            feb_avg_volume, feb_avg_delivery, feb_max_volume, feb_max_delivery,
            feb_min_volume, feb_min_delivery, feb_stddev_volume, feb_stddev_delivery,
            feb_median_volume, feb_median_delivery, feb_p75_volume, feb_p75_delivery,
            feb_p95_volume, feb_p95_delivery, feb_trading_days, feb_avg_price,
            feb_avg_turnover, feb_avg_trades,
            
            volume_exceeded_avg, volume_exceeded_max, volume_exceeded_p75, volume_exceeded_p95,
            delivery_exceeded_avg, delivery_exceeded_max, delivery_exceeded_p75, delivery_exceeded_p95,
            
            volume_tier, delivery_tier, overall_tier,
            
            volume_increase_abs, delivery_increase_abs, volume_increase_pct, delivery_increase_pct,
            volume_vs_stddev, delivery_vs_stddev,
            
            price_change_pct, price_volatility, turnover_increase_pct, trades_increase_pct,
            avg_trade_size_march, avg_trade_size_feb, trade_size_change_pct,
            
            volume_delivery_ratio_march, volume_delivery_ratio_feb, ratio_change_pct,
            price_volume_correlation, is_statistical_outlier, outlier_score,
            
            pattern_type, momentum_score, data_quality_score
        ) VALUES (
            ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?,
            ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?,
            ?, ?, ?, ?, ?, ?, ?, ?,
            ?, ?, ?,
            ?, ?, ?, ?, ?, ?,
            ?, ?, ?, ?, ?, ?, ?,
            ?, ?, ?, ?, ?, ?,
            ?, ?, ?
        )
        """
        
        # Insert in optimized batches
        batch_size = 2000  # Optimized for performance
        total_inserted = 0
        
        try:
            for i in range(0, len(exceedance_records), batch_size):
                batch = exceedance_records[i:i+batch_size]
                cursor.executemany(insert_sql, batch)
                total_inserted += len(batch)
                
                if total_inserted % 10000 == 0:
                    print(f"   üìä Inserted {total_inserted:,} / {len(exceedance_records):,} records...")
                    
            self.db.connection.commit()
            print(f"   ‚úÖ Successfully inserted {len(exceedance_records):,} enhanced records")
            print(f"   üéØ Database: step03_march_vs_february_comparison table ready for analysis")
            
        except Exception as e:
            print(f"   ‚ùå Error during insertion: {str(e)}")
            self.db.connection.rollback()
            raise
    
    def show_results_summary(self):
        """
        Show Comprehensive Analysis Results Summary with Executive Dashboard
        
        COMPREHENSIVE REPORTING FEATURES:
        =================================
        1. Executive Summary: High-level KPIs and insights
        2. Tier Distribution: Multi-tier exceedance breakdown
        3. Pattern Analysis: Trading behavior classification
        4. Statistical Summary: Advanced metrics overview
        5. Top Performers: Highest impact securities
        6. Trend Analysis: Date-wise pattern evolution
        7. Quality Metrics: Data reliability assessment
        """
        print("\n" + "="*80)
        print("üìä ENHANCED MARCH VS FEBRUARY COMPARISON RESULTS - EXECUTIVE DASHBOARD")
        print("="*80)
        
        cursor = self.db.connection.cursor()
        
        # EXECUTIVE SUMMARY
        print("\nüéØ EXECUTIVE SUMMARY")
        print("-"*50)
        
        cursor.execute("SELECT COUNT(*) FROM step03_march_vs_february_comparison")
        total_exceedances = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT symbol) FROM step03_march_vs_february_comparison")
        unique_symbols = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT trade_date) FROM step03_march_vs_february_comparison")
        trading_dates = cursor.fetchone()[0]
        
        print(f"üìà Total Exceedances Found: {total_exceedances:,}")
        print(f"üè¢ Unique Symbols with Activity: {unique_symbols:,}")
        print(f"üìÖ Trading Dates Analyzed: {trading_dates}")
        
        # TIER DISTRIBUTION ANALYSIS
        print("\nüèÜ TIER DISTRIBUTION ANALYSIS")
        print("-"*50)
        
        cursor.execute("""
            SELECT overall_tier, COUNT(*) as count, 
                   ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM step03_march_vs_february_comparison), 2) as percentage
            FROM step03_march_vs_february_comparison
            GROUP BY overall_tier
            ORDER BY 
                CASE overall_tier
                    WHEN 'TIER_4_EXPLOSIVE' THEN 1
                    WHEN 'TIER_3_EXCEPTIONAL' THEN 2
                    WHEN 'TIER_2_SIGNIFICANT' THEN 3
                    WHEN 'TIER_1_STANDARD' THEN 4
                    ELSE 5
                END
        """)
        
        for row in cursor.fetchall():
            tier, count, percentage = row
            print(f"   {tier:20} | {count:8,} records | {percentage:6.2f}%")
        
        # PATTERN CLASSIFICATION ANALYSIS
        print("\nüîç PATTERN CLASSIFICATION ANALYSIS")
        print("-"*50)
        
        cursor.execute("""
            SELECT pattern_type, COUNT(*) as count,
                   ROUND(AVG(momentum_score), 2) as avg_momentum,
                   ROUND(AVG(volume_increase_pct), 2) as avg_vol_increase
            FROM step03_march_vs_february_comparison
            GROUP BY pattern_type
            ORDER BY COUNT(*) DESC
        """)
        
        for row in cursor.fetchall():
            pattern, count, momentum, vol_increase = row
            print(f"   {pattern:20} | {count:8,} | Momentum: {momentum:6.2f} | Vol+: {vol_increase:6.2f}%")
        
        # VOLUME VS DELIVERY EXCEEDANCE BREAKDOWN
        print("\nüìä VOLUME VS DELIVERY EXCEEDANCE BREAKDOWN")
        print("-"*50)
        
        cursor.execute("SELECT COUNT(*) FROM step03_march_vs_february_comparison WHERE volume_exceeded_avg = 1")
        volume_exceedances = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM step03_march_vs_february_comparison WHERE delivery_exceeded_avg = 1")
        delivery_exceedances = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM step03_march_vs_february_comparison WHERE volume_exceeded_avg = 1 AND delivery_exceeded_avg = 1")
        both_exceedances = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM step03_march_vs_february_comparison WHERE volume_exceeded_p95 = 1")
        volume_p95_exceedances = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM step03_march_vs_february_comparison WHERE delivery_exceeded_p95 = 1")
        delivery_p95_exceedances = cursor.fetchone()[0]
        
        print(f"ÔøΩ Volume Exceeded Average: {volume_exceedances:,} ({(volume_exceedances/total_exceedances)*100:.1f}%)")
        print(f"üì¶ Delivery Exceeded Average: {delivery_exceedances:,} ({(delivery_exceedances/total_exceedances)*100:.1f}%)")
        print(f"üéØ Both Volume & Delivery: {both_exceedances:,} ({(both_exceedances/total_exceedances)*100:.1f}%)")
        print(f"üöÄ Volume > 95th Percentile: {volume_p95_exceedances:,}")
        print(f"üìÆ Delivery > 95th Percentile: {delivery_p95_exceedances:,}")
        
        # TOP EXPLOSIVE PERFORMERS (TIER 4)
        print("\nüöÄ TOP 15 EXPLOSIVE PERFORMERS (TIER 4)")
        print("-"*50)
        
        cursor.execute("""
            SELECT TOP 15 symbol, trade_date, march_ttl_trd_qnty, feb_avg_volume,
                   volume_increase_pct, delivery_increase_pct, momentum_score, pattern_type
            FROM step03_march_vs_february_comparison
            WHERE overall_tier = 'TIER_4_EXPLOSIVE'
            ORDER BY momentum_score DESC
        """)
        
        explosive_results = cursor.fetchall()
        if explosive_results:
            for row in explosive_results:
                symbol, trade_date, march_vol, feb_vol, vol_inc, del_inc, momentum, pattern = row
                print(f"   {symbol:12} {trade_date} | Vol: {march_vol:>12,} | +{vol_inc:6.1f}% | Del+{del_inc:6.1f}% | M:{momentum:5.1f} | {pattern}")
        else:
            print("   No TIER_4_EXPLOSIVE performers found")
        
        # TOP VOLUME INCREASES
        print("\nÔøΩ TOP 15 VOLUME INCREASES")
        print("-"*50)
        
        cursor.execute("""
            SELECT TOP 15 symbol, trade_date, march_ttl_trd_qnty, feb_avg_volume, 
                   volume_increase_pct, overall_tier, pattern_type
            FROM step03_march_vs_february_comparison
            WHERE volume_exceeded_avg = 1
            ORDER BY volume_increase_pct DESC
        """)
        
        for row in cursor.fetchall():
            symbol, trade_date, march_vol, feb_vol, vol_inc, tier, pattern = row
            print(f"   {symbol:12} {trade_date} | {march_vol:>12,} vs {feb_vol:>12,} | +{vol_inc:6.1f}% | {tier} | {pattern}")
        
        # TOP DELIVERY INCREASES  
        print("\nüì¶ TOP 15 DELIVERY INCREASES")
        print("-"*50)
        
        cursor.execute("""
            SELECT TOP 15 symbol, trade_date, march_deliv_qty, feb_avg_delivery,
                   delivery_increase_pct, overall_tier, pattern_type
            FROM step03_march_vs_february_comparison
            WHERE delivery_exceeded_avg = 1
            ORDER BY delivery_increase_pct DESC
        """)
        
        for row in cursor.fetchall():
            symbol, trade_date, march_del, feb_del, del_inc, tier, pattern = row
            print(f"   {symbol:12} {trade_date} | {march_del:>12,} vs {feb_del:>12,} | +{del_inc:6.1f}% | {tier} | {pattern}")
        
        # STATISTICAL OUTLIERS
        print("\n‚ö†Ô∏è  STATISTICAL OUTLIERS (TOP 10)")
        print("-"*50)
        
        cursor.execute("""
            SELECT TOP 10 symbol, trade_date, outlier_score, volume_vs_stddev, 
                   delivery_vs_stddev, overall_tier
            FROM step03_march_vs_february_comparison
            WHERE is_statistical_outlier = 1
            ORDER BY outlier_score DESC
        """)
        
        outlier_results = cursor.fetchall()
        if outlier_results:
            for row in outlier_results:
                symbol, trade_date, outlier_score, vol_stddev, del_stddev, tier = row
                print(f"   {symbol:12} {trade_date} | Score: {outlier_score:5.2f} | Vol œÉ: {vol_stddev:5.2f} | Del œÉ: {del_stddev:5.2f} | {tier}")
        else:
            print("   No statistical outliers detected")
        
        # DATE DISTRIBUTION (TOP 15 DATES)
        print("\nüìÖ EXCEEDANCES BY DATE (TOP 15 MOST ACTIVE)")
        print("-"*50)
        
        cursor.execute("""
            SELECT TOP 15 trade_date, COUNT(*) as exceedances,
                   COUNT(CASE WHEN overall_tier = 'TIER_4_EXPLOSIVE' THEN 1 END) as explosive,
                   COUNT(CASE WHEN overall_tier = 'TIER_3_EXCEPTIONAL' THEN 1 END) as exceptional,
                   ROUND(AVG(momentum_score), 2) as avg_momentum
            FROM step03_march_vs_february_comparison
            GROUP BY trade_date
            ORDER BY COUNT(*) DESC
        """)
        
        for row in cursor.fetchall():
            trade_date, exceedances, explosive, exceptional, avg_momentum = row
            print(f"   {trade_date} | {exceedances:>6,} total | T4:{explosive:>4,} | T3:{exceptional:>4,} | Momentum: {avg_momentum:5.2f}")
        
        # DATA QUALITY SUMMARY
        print("\nüîç DATA QUALITY SUMMARY")
        print("-"*50)
        
        cursor.execute("""
            SELECT 
                ROUND(AVG(data_quality_score), 2) as avg_quality,
                MIN(data_quality_score) as min_quality,
                MAX(data_quality_score) as max_quality,
                COUNT(CASE WHEN data_quality_score >= 90 THEN 1 END) as high_quality,
                COUNT(CASE WHEN data_quality_score < 70 THEN 1 END) as low_quality
            FROM step03_march_vs_february_comparison
        """)
        
        quality_row = cursor.fetchone()
        if quality_row:
            avg_qual, min_qual, max_qual, high_qual, low_qual = quality_row
            print(f"   Average Quality Score: {avg_qual}")
            print(f"   Quality Range: {min_qual} - {max_qual}")
            print(f"   High Quality Records (‚â•90): {high_qual:,}")
            print(f"   Low Quality Records (<70): {low_qual:,}")
        
        print("\n" + "="*80)
        print("‚úÖ COMPREHENSIVE ANALYSIS SUMMARY COMPLETE")
        print("="*80)
    
    def export_to_excel(self):
        """
        Export Enhanced Results to Multi-Sheet Excel Workbook
        
        EXCEL EXPORT FEATURES:
        =====================
        1. Executive Summary Sheet: High-level KPIs and charts
        2. Detailed Analysis Sheet: Complete exceedance records
        3. Tier Analysis Sheet: Multi-tier breakdown
        4. Pattern Analysis Sheet: Trading behavior patterns
        5. Statistical Summary Sheet: Advanced metrics
        6. Top Performers Sheet: Highest impact securities
        7. Date Analysis Sheet: Time-series patterns
        
        BUSINESS INTELLIGENCE FEATURES:
        ==============================
        - Formatted tables with conditional formatting
        - Multiple worksheets for different analysis views
        - Export-ready for further analysis tools
        - Comprehensive metadata and documentation
        """
        print("\nüìÑ Exporting Enhanced Results to Multi-Sheet Excel Workbook...")
        
        cursor = self.db.connection.cursor()
        filename = f"march_vs_february_enhanced_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        try:
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                
                # Sheet 1: Executive Summary
                cursor.execute("""
                    SELECT 
                        overall_tier, COUNT(*) as count,
                        ROUND(AVG(momentum_score), 2) as avg_momentum,
                        ROUND(AVG(volume_increase_pct), 2) as avg_vol_increase,
                        ROUND(AVG(delivery_increase_pct), 2) as avg_del_increase
                    FROM step03_march_vs_february_comparison
                    GROUP BY overall_tier
                    ORDER BY 
                        CASE overall_tier
                            WHEN 'TIER_4_EXPLOSIVE' THEN 1
                            WHEN 'TIER_3_EXCEPTIONAL' THEN 2
                            WHEN 'TIER_2_SIGNIFICANT' THEN 3
                            WHEN 'TIER_1_STANDARD' THEN 4
                            ELSE 5
                        END
                """)
                
                summary_data = cursor.fetchall()
                if summary_data:
                    summary_df = pd.DataFrame(summary_data, columns=[
                        'Tier', 'Count', 'Avg Momentum Score', 'Avg Volume Increase %', 'Avg Delivery Increase %'
                    ])
                    summary_df.to_excel(writer, sheet_name='Executive_Summary', index=False)
                
                # Sheet 2: Complete Detailed Analysis
                cursor.execute("""
                    SELECT TOP 50000
                        trade_date, symbol, series, march_ttl_trd_qnty, march_deliv_qty,
                        march_close_price, feb_avg_volume, feb_avg_delivery,
                        volume_exceeded_avg, delivery_exceeded_avg, overall_tier,
                        volume_increase_pct, delivery_increase_pct, momentum_score,
                        pattern_type, price_change_pct, is_statistical_outlier
                    FROM step03_march_vs_february_comparison
                    ORDER BY momentum_score DESC
                """)
                
                detailed_data = cursor.fetchall()
                if detailed_data:
                    detailed_df = pd.DataFrame(detailed_data, columns=[
                        'Trade Date', 'Symbol', 'Series', 'March Volume', 'March Delivery',
                        'March Close Price', 'Feb Avg Volume', 'Feb Avg Delivery',
                        'Volume Exceeded', 'Delivery Exceeded', 'Overall Tier',
                        'Volume Increase %', 'Delivery Increase %', 'Momentum Score',
                        'Pattern Type', 'Price Change %', 'Statistical Outlier'
                    ])
                    detailed_df.to_excel(writer, sheet_name='Detailed_Analysis', index=False)
                
                # Sheet 3: Tier Distribution Analysis
                cursor.execute("""
                    SELECT 
                        volume_tier, delivery_tier, overall_tier, pattern_type,
                        COUNT(*) as count,
                        ROUND(AVG(momentum_score), 2) as avg_momentum,
                        ROUND(AVG(volume_increase_pct), 2) as avg_vol_inc,
                        ROUND(AVG(delivery_increase_pct), 2) as avg_del_inc
                    FROM step03_march_vs_february_comparison
                    GROUP BY volume_tier, delivery_tier, overall_tier, pattern_type
                    ORDER BY COUNT(*) DESC
                """)
                
                tier_data = cursor.fetchall()
                if tier_data:
                    tier_df = pd.DataFrame(tier_data, columns=[
                        'Volume Tier', 'Delivery Tier', 'Overall Tier', 'Pattern Type',
                        'Count', 'Avg Momentum', 'Avg Volume Inc %', 'Avg Delivery Inc %'
                    ])
                    tier_df.to_excel(writer, sheet_name='Tier_Analysis', index=False)
                
                # Sheet 4: Top Performers
                cursor.execute("""
                    SELECT TOP 100
                        symbol, trade_date, overall_tier, pattern_type,
                        march_ttl_trd_qnty, march_deliv_qty, march_close_price,
                        volume_increase_pct, delivery_increase_pct, momentum_score,
                        price_change_pct, is_statistical_outlier, outlier_score
                    FROM step03_march_vs_february_comparison
                    ORDER BY momentum_score DESC
                """)
                
                performers_data = cursor.fetchall()
                if performers_data:
                    performers_df = pd.DataFrame(performers_data, columns=[
                        'Symbol', 'Trade Date', 'Overall Tier', 'Pattern Type',
                        'March Volume', 'March Delivery', 'March Close Price',
                        'Volume Increase %', 'Delivery Increase %', 'Momentum Score',
                        'Price Change %', 'Statistical Outlier', 'Outlier Score'
                    ])
                    performers_df.to_excel(writer, sheet_name='Top_Performers', index=False)
                
                # Sheet 5: Date-wise Analysis
                cursor.execute("""
                    SELECT 
                        trade_date, COUNT(*) as total_exceedances,
                        COUNT(CASE WHEN overall_tier = 'TIER_4_EXPLOSIVE' THEN 1 END) as tier4_count,
                        COUNT(CASE WHEN overall_tier = 'TIER_3_EXCEPTIONAL' THEN 1 END) as tier3_count,
                        COUNT(CASE WHEN pattern_type = 'BREAKOUT' THEN 1 END) as breakout_count,
                        ROUND(AVG(momentum_score), 2) as avg_momentum,
                        ROUND(AVG(volume_increase_pct), 2) as avg_vol_increase
                    FROM step03_march_vs_february_comparison
                    GROUP BY trade_date
                    ORDER BY trade_date
                """)
                
                date_data = cursor.fetchall()
                if date_data:
                    date_df = pd.DataFrame(date_data, columns=[
                        'Trade Date', 'Total Exceedances', 'Tier 4 Count', 'Tier 3 Count',
                        'Breakout Count', 'Avg Momentum', 'Avg Volume Increase %'
                    ])
                    date_df.to_excel(writer, sheet_name='Date_Analysis', index=False)
                
                print(f"   ‚úÖ Excel export completed: {filename}")
                print(f"   üìä Sheets created: Executive_Summary, Detailed_Analysis, Tier_Analysis, Top_Performers, Date_Analysis")
                
        except Exception as e:
            print(f"   ‚ùå Error during Excel export: {str(e)}")
            print("   üí° Tip: Ensure pandas and openpyxl are installed")
    
    def create_business_intelligence_views(self):
        """
        Create SQL Views for Business Intelligence and Reporting
        
        VIEWS CREATED:
        =============
        1. vw_march_top_performers: Top performing securities by momentum
        2. vw_march_tier_summary: Tier distribution summary
        3. vw_march_pattern_analysis: Pattern-based analysis
        4. vw_march_date_trends: Date-wise trend analysis
        5. vw_march_outlier_analysis: Statistical outlier summary
        """
        print("\nüîß Creating Business Intelligence SQL Views...")
        
        cursor = self.db.connection.cursor()
        
        # View 1: Top Performers
        cursor.execute("""
            IF OBJECT_ID('vw_march_top_performers', 'V') IS NOT NULL
                DROP VIEW vw_march_top_performers
        """)
        
        cursor.execute("""
            CREATE VIEW vw_march_top_performers AS
            SELECT TOP 1000
                symbol, trade_date, overall_tier, pattern_type,
                march_ttl_trd_qnty, march_deliv_qty, march_close_price,
                volume_increase_pct, delivery_increase_pct, momentum_score,
                price_change_pct, volume_vs_stddev, delivery_vs_stddev
            FROM step03_march_vs_february_comparison
            ORDER BY momentum_score DESC
        """)
        
        # View 2: Tier Summary
        cursor.execute("""
            IF OBJECT_ID('vw_march_tier_summary', 'V') IS NOT NULL
                DROP VIEW vw_march_tier_summary
        """)
        
        cursor.execute("""
            CREATE VIEW vw_march_tier_summary AS
            SELECT 
                overall_tier,
                COUNT(*) as total_records,
                COUNT(DISTINCT symbol) as unique_symbols,
                ROUND(AVG(momentum_score), 2) as avg_momentum,
                ROUND(AVG(volume_increase_pct), 2) as avg_volume_increase,
                ROUND(AVG(delivery_increase_pct), 2) as avg_delivery_increase,
                MAX(volume_increase_pct) as max_volume_increase,
                MAX(delivery_increase_pct) as max_delivery_increase
            FROM step03_march_vs_february_comparison
            GROUP BY overall_tier
        """)
        
        # View 3: Pattern Analysis
        cursor.execute("""
            IF OBJECT_ID('vw_march_pattern_analysis', 'V') IS NOT NULL
                DROP VIEW vw_march_pattern_analysis
        """)
        
        cursor.execute("""
            CREATE VIEW vw_march_pattern_analysis AS
            SELECT 
                pattern_type,
                overall_tier,
                COUNT(*) as pattern_count,
                ROUND(AVG(momentum_score), 2) as avg_momentum,
                ROUND(AVG(price_change_pct), 2) as avg_price_change,
                COUNT(CASE WHEN is_statistical_outlier = 1 THEN 1 END) as outlier_count
            FROM step03_march_vs_february_comparison
            GROUP BY pattern_type, overall_tier
        """)
        
        # View 4: Date Trends
        cursor.execute("""
            IF OBJECT_ID('vw_march_date_trends', 'V') IS NOT NULL
                DROP VIEW vw_march_date_trends
        """)
        
        cursor.execute("""
            CREATE VIEW vw_march_date_trends AS
            SELECT 
                trade_date,
                COUNT(*) as daily_exceedances,
                COUNT(DISTINCT symbol) as unique_symbols,
                COUNT(CASE WHEN overall_tier IN ('TIER_3_EXCEPTIONAL', 'TIER_4_EXPLOSIVE') THEN 1 END) as high_tier_count,
                ROUND(AVG(momentum_score), 2) as avg_momentum,
                ROUND(AVG(volume_increase_pct), 2) as avg_volume_increase
            FROM step03_march_vs_february_comparison
            GROUP BY trade_date
        """)
        
        self.db.connection.commit()
        print(f"   ‚úÖ Created 4 Business Intelligence Views")
        print(f"   üìä Views: vw_march_top_performers, vw_march_tier_summary, vw_march_pattern_analysis, vw_march_date_trends")
    
    def run_complete_analysis(self):
        """
        Execute Complete Enhanced March vs February Analysis
        
        COMPREHENSIVE ANALYSIS PIPELINE:
        ===============================
        Phase 1: Initialization and Setup
        ‚îú‚îÄ‚îÄ Configuration validation
        ‚îú‚îÄ‚îÄ Database table preparation
        ‚îî‚îÄ‚îÄ Analysis parameter setup
        
        Phase 2: Statistical Baseline Calculation
        ‚îú‚îÄ‚îÄ February 2025 data aggregation
        ‚îú‚îÄ‚îÄ Multi-dimensional statistical analysis
        ‚îú‚îÄ‚îÄ Quality validation and scoring
        ‚îî‚îÄ‚îÄ Percentile threshold calculation
        
        Phase 3: March Data Processing
        ‚îú‚îÄ‚îÄ Daily record loading with quality checks
        ‚îú‚îÄ‚îÄ Multi-tier exceedance detection
        ‚îú‚îÄ‚îÄ Advanced pattern recognition
        ‚îú‚îÄ‚îÄ Statistical significance testing
        ‚îî‚îÄ‚îÄ Comprehensive metric calculation
        
        Phase 4: Results Generation and Reporting
        ‚îú‚îÄ‚îÄ Database record insertion
        ‚îú‚îÄ‚îÄ Executive dashboard generation
        ‚îú‚îÄ‚îÄ Multi-sheet Excel export
        ‚îú‚îÄ‚îÄ Business Intelligence view creation
        ‚îî‚îÄ‚îÄ Analysis summary and recommendations
        
        BUSINESS VALUE DELIVERY:
        =======================
        - Identify high-momentum securities
        - Detect unusual trading patterns  
        - Support investment decision making
        - Enable algorithmic trading strategies
        - Provide regulatory compliance data
        - Generate actionable business insights
        """
        print("üöÄ STEP 03B: ENHANCED MARCH 2025 vs FEBRUARY 2025 COMPREHENSIVE ANALYSIS")
        print("="*90)
        print("üìã METHODOLOGY: Multi-tier statistical analysis with advanced pattern recognition")
        print("üéØ OBJECTIVE: Identify securities with exceptional March trading activity vs February baselines")
        print("üìä FEATURES: Tier classification, outlier detection, momentum scoring, pattern analysis")
        print("üîç QUALITY: Statistical validation, data quality scoring, comprehensive reporting")
        print()
        
        try:
            # Phase 1: Process comprehensive comparisons
            print("üìà PHASE 1: COMPREHENSIVE COMPARISON PROCESSING")
            exceedance_records = self.process_march_vs_february_comparison()
            
            # Phase 2: Insert enhanced records
            print("\nüíæ PHASE 2: DATABASE RECORD INSERTION")
            self.insert_exceedance_records(exceedance_records)
            
            # Phase 3: Generate executive dashboard
            print("\nüìä PHASE 3: EXECUTIVE DASHBOARD GENERATION")
            self.show_results_summary()
            
            # Phase 4: Create business intelligence assets
            print("\nüìÑ PHASE 4: BUSINESS INTELLIGENCE ASSET CREATION")
            self.export_to_excel()
            self.create_business_intelligence_views()
            
            print(f"\n‚úÖ ENHANCED MARCH VS FEBRUARY ANALYSIS COMPLETE!")
            print("="*90)
            print(f"üìä DATABASE TABLE: step03_march_vs_february_comparison")
            print(f"üìà EXCEL EXPORT: march_vs_february_enhanced_analysis_[timestamp].xlsx") 
            print(f"üîç BI VIEWS: vw_march_top_performers, vw_march_tier_summary, and more")
            print(f"üéØ READY FOR: Advanced querying, business intelligence, and strategic analysis")
            print("="*90)
            
        except Exception as e:
            print(f"\n‚ùå ANALYSIS ERROR: {str(e)}")
            print("üí° Check database connectivity and data availability")
            raise
    
    def close(self):
        """Close database connection"""
        self.db.close()

def main():
    analyzer = Step03MarchVsFebruaryAnalyzer()
    try:
        analyzer.run_complete_analysis()
    finally:
        analyzer.close()

if __name__ == '__main__':
    main()