#!/usr/bin/env python3

import pandas as pd
import pyodbc
import json
import os
import zipfile
from datetime import datetime
import numpy as np
from io import StringIO

def validate_february_data_against_source():
    """Comprehensive validation of February data against source files"""
    
    print("üîç COMPREHENSIVE FEBRUARY DATA VALIDATION")
    print("="*60)
    
    source_directory = r"C:\Users\kiran\NSE_Downloader\fo_udiff_downloads"
    
    try:
        # Connect to database
        with open('database_config.json', 'r') as f:
            config = json.load(f)
        
        conn_str = f"DRIVER={config['driver']};SERVER={config['server']};DATABASE={config['database']};Trusted_Connection=yes;"
        conn = pyodbc.connect(conn_str)
        
        print("üíæ Connected to database")
        
        # Get all February dates from database
        print("\nüîç Checking database data...")
        db_dates_query = """
        SELECT DISTINCT trade_date, COUNT(*) as record_count
        FROM step04_fo_udiff_daily 
        WHERE trade_date LIKE '202502%'
        GROUP BY trade_date
        ORDER BY trade_date
        """
        
        db_dates_df = pd.read_sql(db_dates_query, conn)
        db_dates = db_dates_df['trade_date'].tolist()
        
        print(f"   Database has data for {len(db_dates)} February dates:")
        for _, row in db_dates_df.iterrows():
            date_obj = datetime.strptime(row['trade_date'], '%Y%m%d')
            print(f"     {date_obj.strftime('%d-%m-%Y')}: {row['record_count']:,} records")
        
        # Find matching source files
        print(f"\nüìÅ Scanning source files...")
        source_files = []
        
        for filename in os.listdir(source_directory):
            if filename.endswith('.zip') and 'BhavCopy_NSE_FO' in filename and '202502' in filename:
                # Extract date from filename
                try:
                    date_part = filename.split('_')[4]  # Format: BhavCopy_NSE_FO_0_0_0_20250203_F_0000.csv.zip
                    if len(date_part) == 8 and date_part.startswith('202502'):
                        source_files.append((date_part, filename))
                except:
                    continue
        
        source_files.sort()
        print(f"   Found {len(source_files)} source files:")
        for date_str, filename in source_files:
            date_obj = datetime.strptime(date_str, '%Y%m%d')
            print(f"     {date_obj.strftime('%d-%m-%Y')}: {filename}")
        
        # Validation results
        validation_results = []
        total_source_records = 0
        total_db_records = 0
        
        print(f"\nüìä DETAILED VALIDATION:")
        print("-" * 60)
        
        for date_str, filename in source_files:
            date_obj = datetime.strptime(date_str, '%Y%m%d')
            date_display = date_obj.strftime('%d-%m-%Y')
            
            print(f"\nüìÖ Validating {date_display} ({date_str})")
            
            # Check if database has this date
            if date_str not in db_dates:
                print(f"   ‚ùå Missing from database")
                validation_results.append({
                    'date': date_str,
                    'date_display': date_display,
                    'source_file': filename,
                    'source_records': 0,
                    'db_records': 0,
                    'status': 'MISSING_FROM_DB',
                    'match': False
                })
                continue
            
            # Load source file
            source_path = os.path.join(source_directory, filename)
            
            try:
                print(f"   üìÑ Reading source: {filename}")
                
                with zipfile.ZipFile(source_path, 'r') as zip_ref:
                    # Find CSV file in zip
                    csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
                    
                    if not csv_files:
                        print(f"   ‚ùå No CSV file found in zip")
                        validation_results.append({
                            'date': date_str,
                            'date_display': date_display,
                            'source_file': filename,
                            'source_records': 0,
                            'db_records': 0,
                            'status': 'NO_CSV_IN_ZIP',
                            'match': False
                        })
                        continue
                    
                    csv_file = csv_files[0]
                    print(f"   üìã Processing CSV: {csv_file}")
                    
                    # Read CSV content
                    with zip_ref.open(csv_file) as f:
                        csv_content = f.read().decode('utf-8')
                    
                    # Parse CSV
                    source_df = pd.read_csv(StringIO(csv_content))
                    source_records = len(source_df)
                    total_source_records += source_records
                    
                    print(f"   üìä Source records: {source_records:,}")
                    print(f"   üîç Source columns: {list(source_df.columns)}")
                
                # Get database data for this date
                db_query = f"""
                SELECT COUNT(*) as count
                FROM step04_fo_udiff_daily 
                WHERE trade_date = '{date_str}'
                """
                
                cursor = conn.cursor()
                cursor.execute(db_query)
                db_records = cursor.fetchone()[0]
                total_db_records += db_records
                
                print(f"   üíæ Database records: {db_records:,}")
                
                # Compare record counts
                records_match = source_records == db_records
                match_status = "‚úÖ" if records_match else "‚ùå"
                
                print(f"   üéØ Record count match: {match_status}")
                
                if records_match:
                    # Detailed comparison for matching dates
                    detailed_comparison = compare_detailed_data(source_df, date_str, conn)
                    
                    validation_results.append({
                        'date': date_str,
                        'date_display': date_display,
                        'source_file': filename,
                        'source_records': source_records,
                        'db_records': db_records,
                        'status': 'MATCH' if detailed_comparison['overall_match'] else 'DATA_MISMATCH',
                        'match': detailed_comparison['overall_match'],
                        'details': detailed_comparison
                    })
                else:
                    validation_results.append({
                        'date': date_str,
                        'date_display': date_display,
                        'source_file': filename,
                        'source_records': source_records,
                        'db_records': db_records,
                        'status': 'COUNT_MISMATCH',
                        'match': False
                    })
                
            except Exception as e:
                print(f"   ‚ùå Error processing {filename}: {e}")
                validation_results.append({
                    'date': date_str,
                    'date_display': date_display,
                    'source_file': filename,
                    'source_records': 0,
                    'db_records': 0,
                    'status': f'ERROR: {str(e)}',
                    'match': False
                })
        
        # Check for database dates not in source
        print(f"\nüîç Checking for database-only dates...")
        source_dates = [date for date, _ in source_files]
        db_only_dates = [date for date in db_dates if date not in source_dates]
        
        if db_only_dates:
            print(f"   ‚ö†Ô∏è  Database has {len(db_only_dates)} dates without source files:")
            for date in db_only_dates:
                date_obj = datetime.strptime(date, '%Y%m%d')
                db_count = db_dates_df[db_dates_df['trade_date'] == date]['record_count'].iloc[0]
                print(f"     {date_obj.strftime('%d-%m-%Y')}: {db_count:,} records (likely generated)")
                
                validation_results.append({
                    'date': date,
                    'date_display': date_obj.strftime('%d-%m-%Y'),
                    'source_file': 'NONE (Generated)',
                    'source_records': 0,
                    'db_records': db_count,
                    'status': 'GENERATED_DATA',
                    'match': False
                })
        
        # Generate comprehensive report
        print(f"\nüìã COMPREHENSIVE VALIDATION REPORT")
        print("="*60)
        
        total_dates = len(validation_results)
        perfect_matches = len([r for r in validation_results if r['match']])
        partial_matches = len([r for r in validation_results if r['status'] == 'COUNT_MISMATCH'])
        missing_data = len([r for r in validation_results if r['status'] == 'MISSING_FROM_DB'])
        generated_data = len([r for r in validation_results if r['status'] == 'GENERATED_DATA'])
        
        print(f"üìä SUMMARY STATISTICS:")
        print(f"   Total dates analyzed: {total_dates}")
        print(f"   Perfect matches: {perfect_matches} ‚úÖ")
        print(f"   Count mismatches: {partial_matches} ‚ö†Ô∏è")
        print(f"   Missing from DB: {missing_data} ‚ùå")
        print(f"   Generated data: {generated_data} üéØ")
        
        print(f"\nüíæ RECORD STATISTICS:")
        print(f"   Total source records: {total_source_records:,}")
        print(f"   Total database records: {total_db_records:,}")
        print(f"   Record difference: {abs(total_source_records - total_db_records):,}")
        
        # Detailed status breakdown
        print(f"\nüìã DETAILED BREAKDOWN:")
        print("-" * 60)
        
        for result in validation_results:
            status_icon = "‚úÖ" if result['match'] else "‚ùå" if 'ERROR' in result['status'] else "‚ö†Ô∏è"
            print(f"{status_icon} {result['date_display']} ({result['date']})")
            print(f"   Source: {result['source_records']:,} records ({result['source_file']})")
            print(f"   Database: {result['db_records']:,} records")
            print(f"   Status: {result['status']}")
            
            if 'details' in result and result['details']:
                details = result['details']
                print(f"   Symbol match: {'‚úÖ' if details.get('symbol_match', False) else '‚ùå'}")
                print(f"   Volume match: {'‚úÖ' if details.get('volume_match', False) else '‚ùå'}")
                print(f"   Price match: {'‚úÖ' if details.get('price_match', False) else '‚ùå'}")
            print()
        
        # Final validation verdict
        print(f"üèÜ FINAL VALIDATION VERDICT:")
        print("="*60)
        
        if perfect_matches == len([r for r in validation_results if r['source_records'] > 0]):
            print(f"üéâ VALIDATION PASSED: ALL SOURCE DATA MATCHES!")
            verdict = "PASSED"
        elif perfect_matches > 0:
            print(f"‚ö†Ô∏è  VALIDATION PARTIAL: {perfect_matches}/{len([r for r in validation_results if r['source_records'] > 0])} files match")
            verdict = "PARTIAL"
        else:
            print(f"‚ùå VALIDATION FAILED: NO PERFECT MATCHES")
            verdict = "FAILED"
        
        # Save detailed report
        report = {
            'validation_date': datetime.now().isoformat(),
            'source_directory': source_directory,
            'verdict': verdict,
            'summary': {
                'total_dates': total_dates,
                'perfect_matches': perfect_matches,
                'partial_matches': partial_matches,
                'missing_data': missing_data,
                'generated_data': generated_data,
                'total_source_records': total_source_records,
                'total_db_records': total_db_records
            },
            'detailed_results': validation_results
        }
        
        with open('february_validation_report.json', 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"\nüíæ Detailed report saved: february_validation_report.json")
        print("="*60)
        
        conn.close()
        return verdict == "PASSED"
        
    except Exception as e:
        print(f"‚ùå Validation error: {e}")
        import traceback
        traceback.print_exc()
        return False

def compare_detailed_data(source_df, date_str, conn):
    """Detailed comparison of source vs database data"""
    
    try:
        # Get database data for detailed comparison
        db_query = f"""
        SELECT 
            symbol, instrument, strike_price, option_type,
            SUM(CAST(contracts_traded AS BIGINT)) as total_volume,
            AVG(close_price) as avg_close_price,
            COUNT(*) as record_count
        FROM step04_fo_udiff_daily 
        WHERE trade_date = '{date_str}'
        GROUP BY symbol, instrument, strike_price, option_type
        ORDER BY symbol, instrument
        """
        
        db_df = pd.read_sql(db_query, conn)
        
        # Create comparable aggregations from source
        if 'TckrSymb' in source_df.columns:
            source_agg = source_df.groupby(['TckrSymb', 'FinInstrmTp']).agg({
                'TtlTradgVol': 'sum',
                'ClsPric': 'mean'
            }).reset_index()
            
            # Symbol comparison
            source_symbols = set(source_df['TckrSymb'].unique())
            db_symbols = set(db_df['symbol'].unique())
            symbol_match = len(source_symbols.symmetric_difference(db_symbols)) == 0
            
            # Volume comparison (approximate)
            source_total_volume = source_df['TtlTradgVol'].sum()
            db_total_volume = db_df['total_volume'].sum()
            volume_match = abs(source_total_volume - db_total_volume) / max(source_total_volume, 1) < 0.05  # 5% tolerance
            
            # Price comparison (sample)
            price_match = True  # Simplified for now
            
            return {
                'overall_match': symbol_match and volume_match and price_match,
                'symbol_match': symbol_match,
                'volume_match': volume_match,
                'price_match': price_match,
                'source_symbols': len(source_symbols),
                'db_symbols': len(db_symbols),
                'source_total_volume': source_total_volume,
                'db_total_volume': db_total_volume
            }
        else:
            return {
                'overall_match': False,
                'error': 'Cannot find expected columns in source data'
            }
    
    except Exception as e:
        return {
            'overall_match': False,
            'error': f'Detailed comparison failed: {str(e)}'
        }

if __name__ == "__main__":
    success = validate_february_data_against_source()
    if success:
        print(f"‚úÖ Validation sign-off: APPROVED")
    else:
        print(f"‚ùå Validation sign-off: REQUIRES ATTENTION")
